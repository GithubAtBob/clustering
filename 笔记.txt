数据量很大，缺失值较少：因为有足够的数据量，删除小部分数据可能对结果影响不大，因此这种情况我可能把缺失数据对应的行删除。
数据量很大，缺失值较多：如果这个特征很重要，可能需要做一下插值，如果这个特征不是很重要，我会把整个特征删掉。



离散特征的编码分为两种情况：
1、离散特征的取值之间没有大小的意义，比如color：[red,blue],那么就使用one-hot编码
2、离散特征的取值有大小的意义，比如size:[X,XL,XXL],那么就使用数值的映射{X:1,XL:2,XXL:3}

标准化通常是为了消除量纲的影响。
标准差标准化(Z_score标准化):标准化后的数据符合标准正态分布，即均值为0，标准差为1。
x’=(x-μ)/σ，其中μ为所有样本数据的均值，σ为所有样本数据的标准差。
离差标准化(Max-Min标准化):把数值缩放到[0,1]区间里面。
x’=(x-min)/(max-min)，其中max为样本的最大值，min为样本的最小值。


Minkowski inequality

过程挖掘的出发点是事件日志(event log)。

在分类算法进行以前，我们应该决定哪一列才是分类目标，然后采用决策树等算法。
而对于过程挖掘，我们有略微不同的分析模型，因为我们从过程的角度来看待数据。
在过程挖掘的数据集中，每一个独立的行不代表一个完整的过程实例，而仅仅是一个事件。
因为一个用作过程挖掘的数据集由许多事件构成，所以这种类型的数据指代事件日志。
在一个事件日志中:每个事件指代按过程执行的一个事件;多个事件通过caseId连接在一起;
逻辑上说，每个示例组成了一系列的事件――以他们的时间戳排序。

事件日志的最少要求:实例Id(caseId),时间戳(timestamp),活动描述(activity)
一个事件定义成一个元组(a,c,t, (d1,v1), . . . ,(dm,vm)),a是活动名,c是实例Id,t是时间戳，
 (d1,v1), . . . ,(dm,vm)(m>=0)是事件的属性和它们的值。

过程挖掘是一门新兴的学科，最近十年有重大的发展。
预测业务流程监测(Predictive business process monitoring)是过程挖掘的一个分支，旨在
在运行时预测并且尽早地根据未完成的路径分析出运行的结果。

聚类是统计数据分析的一种重要的工具。它的主要目标是把同质的数据样本归为同一簇。
一个好的聚类结果能够把相似度高的样本聚成一簇，而把相似度低的样本划分成不同的簇。
根据聚类原理，可将聚类方法分为以下几种：划分方法(Partitioning Method),层次法(Hierarchical Methods),
基于密度的方法(Denisity-based Methods),基于网格的方法(Grid-based Methods),
基于模型的方法(Model-based Methods),模糊聚类方法(Fuzzy Clustering Methods)

不同数据对象的特征矢量放在不同的行，就形成一个n*d的数据矩阵，n表示数据对象的数目，d表示特征的数目。
这种数据表示方式将不同种类的数据对象转换成相同的标准表示形式，如果所有的特征都是数值型的，
那么一个对象就可以表示成在d维空间中的一个点，就可以用不同的算法加以分析。特征的类型主要包括以下几种：
1.名词型(Nominal):其特点是离散的，无序的。就如原始数据中的乘客Id,司机Id,订单状态等。
2.序数型(Ordinal):其特点是离散的，有序的。就如原始数据中的车型(出租车,网约车,商务七座等)
3.区间型(Interval):其特点是连续的。
4.比例型(Ratio):其特点是连续的。就如原始数据中的订单金额，乘客人数等。
5.数值型(Numerical):连续的，可以是正值，零和负值。


在聚类算法中怎么量化高维？许多聚类算法能够在维数d<=16的数据集中有效的工作，
当数据的维数d>20时，聚类算法的性能显著地降低。因此，可以认为超过16维属性的数据就是高维数据。
高维数据使得计算成本急剧增加，数据可视化变得不可行，同时带来了数据对象的可分析性问题。


传统聚类方法对高维数据聚类主要遇到两个问题:
1.高维数据集存在大量无关属性，使得所有维中存在簇的可能性几乎为零，
2.高维空间数据分布相比低维空间数据要稀疏，所以很多数据间距离几乎相等，
因此，传统的基于距离的聚类方法在高维空间中行不通。


聚类方法一般包括四个步骤：
1.特征选择或特征抽取。这是一个预处理的过程，它是为了提取能够恰当表示样本的属性，为后面的步骤做准备。
特征选择方法从所有特征集合里面挑选最有力的特征，更容易保留特征本身的原始物理意义;而特征抽取用特征转换的方法从原始特征中产生新的特征。
2.设计聚类算法或者选择一个聚类方法。来计算相似度，得到良好的划分。
3.聚类验证。
4.聚类结果的解释。

已有的线性维数约减方法主要包括主成分分析，随机映射，独立成分分析，线性判别分析等等。
这些方法实际上是在不同优化准则下寻找最佳线性模型，这也是线性维数约减方法的共性。
而目前主要存在的非线性维数约减分别是基于核的方法(Kernel-based Methods)和流形学习(Manifold Learning)。


聚类的定义：给定一组样本集合x={X1,X2,...,Xn}，假定每个样本Xi都有d个特征，
聚类分析就是要根据样本的特征来衡量样本间的相似性，根据某一特定的规则来获取最终的结果。
硬聚类(Hard Clustering)把数据集划分成k个不相交的簇；而模糊聚类(Fuzzy Clustering)只给出每个样本隶属与各个簇的程度。

聚类算法是基于距离来分析潜在的数据分布的。
但是，不同种类的距离在揭露集合性质与数据的相互分布上表现出不同的能力，高维的数据集上更加显著。

我们处理数据使得它们能够用于机器学习算法，来尽快地预测未预料到的结果。

主成分分析就是将包含信息量大的维度保留下来，忽略对数据描述不重要的成分。
即将主成分维度组成的向量空间作为低维空间，完成了降维。

预测问题被分为两个阶段:首先，根据控制流程信息对先前已完成的案例进行聚类；
其次，使用对每个簇使用利用事件数据属性的分类器来区分实现的事件与引发冲突的事件。

PCA要使得数据集中各属性之间没有相关性。当单位不同时，协方差不表示相关程度，要用相关系数来描述ρ=Cov(X,Y)/σxσy。
相关系数是一种剔除了两个变量量纲影响、标准化后的特殊协方差。因此，PCA之前要将数据标准化。